<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Karin Dijkstra, Anastasia Dryaeva, Rick Ploeg &amp; Oliver Strik Propaedeutic Project: A11 Rijksuniversiteit Groningen" />
  <title>Tea with a Travelling Salesman: A Discussion of Genetic Algorithms</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Tea with a Travelling Salesman:<br />
A Discussion of Genetic Algorithms</h1>
<p class="author">Karin Dijkstra, Anastasia Dryaeva, Rick Ploeg &amp; Oliver Strik<br />
Propaedeutic Project: A11<br />
Rijksuniversiteit Groningen</p>
<p class="date">June 16 2017</p>
</header>
<h1 id="introduction">Introduction</h1>
<p>The Travelling Salesman Problem (TSP) is a famous problem in combinatorial optimization, with the goal to minimize the total travel cost (be that time, distance, or fuel expenses) for a salesman who has to visit a finite number of cities and return to the starting point, given the costs associated with travelling from one city to another.</p>
<p>At first the problem may appear uncomplicated and straightforward, however its simplicity is only an illusion. Although the exact origins of the TSP are unclear, it can be dated back to at least 1832, yet to this day, there has been no effective solution method found for a general case. In fact, a solution of this problem would resolve the infamous P vs. NP Millennium Prize problem. As a result, the Travelling Salesman Problem still remains one of the most intensely studied problems in computational mathematics and in the recent years has sparked interests in newer fields, such as computer science.</p>
<p>Throughout the years, different methods and algorithms have been developed for the TSP. Many of the traditional methods involve heuristics such as Nearest Neighbor or Nearest Insertion, or relaxations, for example the Hungarian Algorithm. However, these do not necessarily give the optimal, and for the latter sometimes not even a feasible solution. Moreover, these methods become insufficient when the problem takes a larger scale. An example of a more advanced, newer method would be the application of a Genetic Algorithm. Genetic Algorithms (GAs) are algorithms designed to simulate natural evolution: they are based on the concept of ‘survival of the fittest’.</p>
<p>This article will address the topic of applying a Genetic Algorithm to the Travelling Salesman Problem, focusing on the following question: “How do Genetic Algorithms perform when applied to the Travelling Salesman Problem?”. In order to provide an answer to this question, the TSP will be discussed in more detail in section <a href="#IntroTSP" data-reference-type="ref" data-reference="IntroTSP">2</a>. After that, the general concept of a GA will be explained in section <a href="#WisGA" data-reference-type="ref" data-reference="WisGA">3</a>, including an insight into the construction of such an algorithm for the TSP. In section <a href="#SimpleTSP" data-reference-type="ref" data-reference="SimpleTSP">4</a> the constructed GA will be applied to a small problem of 6 cities, where the efficiency of the algorithm will be evaluated in comparison to the traditional methods. Section <a href="#largeTSP" data-reference-type="ref" data-reference="largeTSP">5</a> will focus on investigating the performance of the GA on an expanded problem of 26 cities, including a discussion of the issues encountered, followed by a detailed analysis of the parameters within the constructed GA in section <a href="#Analysis" data-reference-type="ref" data-reference="Analysis">6</a>. In the final section conclusions will be made, addressing the initial research question.</p>
<h1 id="IntroTSP">What is the Travelling Salesman Problem?</h1>
<p>In 1832, a German handbook for travelling salesmen was published, titled <em>Der Handlungsreisende - wie er sein soll und was er zu tun hat, um Auftr<span>ä</span>ge zu erhalten und eines gl<span>ü</span>cklichen Erfolgs in seinen Gesch<span>ä</span>ften gewi<span>ß</span> zu sein - Von einem alten Commis-Voyageur</em> (translated from German: “The Travelling Salesman - how he should be and what he has to do, in order to obtain commissions and to be assured of great success in his business - by an old Commis-Voyageur”)<span class="citation" data-cites="tspbook"></span>. The book contains a definition and an elaborate description of the problem, as well as the first ever recorded reference to it as “the Travelling Salesman Problem”, but does not give a mathematical treatment for it. Nevertheless, the author clearly recognizes its importance, writing the following passage:</p>
<p>“Business leads the traveling salesman here and there, and there is not a good tour for all occurring cases; but through an expedient choice and division of the tour so much time can be won that we feel compelled to give guidelines about this. Everyone should use as much of the advice as he thinks useful for his application. We believe we can ensure as much that it will not be possible to plan the tours through Germany in consideration of the distances and the traveling back and forth, which deserves the traveler’s special attention, with more economy. The main thing to remember is always to visit as many localities as possible without having to touch them twice.” <span class="citation" data-cites="tspbook"></span></p>
<p>Indeed, the main objective of the TSP is to economize, be that minimizing time, distance, fuel costs or any other expenses a travelling salesman may encounter. However, nowadays the applications of the TSP are recognized to reach far beyond travelling salesmen business. Naturally, the TSP arises in planning, transportation and logistics, problems like designing delivery routes or bus schedules are classic examples of that. There are also numerous applications in everyday life, for example for tourists wanting to visit many historical sites in a limited time, or a person running errands around town. Some other more curious and non-intuitive areas where the TSP has found applications are genetics, manufacturing, telecommunications, and neuroscience <span class="citation" data-cites="tspbook"></span> <span class="citation" data-cites="ORlecture"></span>. Seeing as the TSP is so widely applicable in many areas of both industrial and day-to-day life, an effective method of solution is highly desired, yet for centuries many mathematicians have struggled to find one.</p>
<p>A solution to any Traveling Salesman Problem can without a doubt be obtained by simply listing all the possible tours and selecting the best one. This would indeed always work, as every scenario with Euclidian distances will always have one or more minimal cost tours. However, it must be noted, that the number of possible tours in a TSP is: <br /><span class="math display">$$\frac{(n-1)!}{2}.$$</span><br /> In this equation <span class="math inline"><em>n</em></span> is the number of vertices (referred to in this work as cities). This comes from the fact that at every city the travelling salesman visits, he faces a choice of the remaining cities for his next destination, and the distance between every pair of cities is the same in each direction, forming what is called a ‘symmetric TSP’. Hence, for 5 cities one would find 12 possible tours, 181440 tours for 10 cities, 608225502004416000 tours for 20 and so on. For an asymmetric case, the results are even more dramatic, since the number of possible tours becomes <span class="math inline">(<em>n</em> − 1)!</span>.</p>
<p>Computing all the possible tours on a TSP becomes a huge burden, even when the problem in question is still relatively small. That is why mathematicians and computer scientists have been working on finding more efficient methods to solve the problem. Many methods have been developed, but not one of them is perfect and without drawbacks. One of the relatively successful recently developed methods is solving the problem via Genetic Algorithms.</p>
<h1 id="WisGA">What is a Genetic Algorithm?</h1>
<figure>
<img src="GA_Structure" id="struct" style="width:50.0%" alt="" /><figcaption>The basic structure of a Genetic Algorithm.<span label="struct"></span></figcaption>
</figure>
<p>A Genetic Algorithm is an algorithm that uses natural selection, or survival of the fittest, to find a solution to a problem. All Genetic Algorithms follow a similar, if not identical structure (figure <a href="#struct" data-reference-type="ref" data-reference="struct">1</a>). However, the elements of this structure are highly customised for each specific application. Before going into detail about these elements, the concept of chromosomes and fitness must first be introduced.</p>
<p>Chromosomes are one of the most important parts of a GA, their only purpose is to store the potential solutions of the problem. How chromosomes store these solutions is up to the constructor of the GA, commonly however they are a single string that might represent a binary number, or possibly a list of the problem’s variables. The components that make up the chromosome are referred to as genes, for example in a chromosome described as a binary number, each 1 or 0 is a gene. In the research algorithm a chromosome is a tour. Each city in the given Travelling Salesman Problem is a gene, and the order of the genes in the chromosome describes the order that the cities should be visited in. Another thing to note about chromosomes is their fitness. The fitness function of a GA describes how fit a particular chromosome is as a solution. How this fitness works and how fitnesses are compared, is again nearly entirely up to the constructor of the GA.</p>
<h2 id="initialisation-of-the-pool">Initialisation of the Pool</h2>
<p>The first step in the execution of a Genetic Algorithm is the generation of the pool. The pool is a collection of chromosomes that can be described as the “current generation”. This pool is initialised by randomly generating chromosomes until the pool is filled, in the case of the research algorithm, this was done by shuffling the list of cities to construct a tour. Shuffling a list that contains each city only once eliminates the possibility of missing or having duplicate cities within the chromosome which is one of the constraints of the Travelling Salesman Problem. The number of chromosomes in the pool is usually a fixed number, however adaptive pool sizing does exist <span class="citation" data-cites="populationsize"></span>. However only fixed pool size was used in this research.</p>
<h2 id="the-main-loop">The Main Loop</h2>
<p>This next section comprises the main body of the GA. Every time this loop is completed, a generation has passed. Throughout the next sections, the methods used in the research algorithm will be used as examples.</p>
<h3 id="parents">Parent Selection</h3>
<p>Parent selection is the first step of each generation. The flow of Figure <a href="#struct" data-reference-type="ref" data-reference="struct">1</a> suggests that all parents are selected before Crossover, however in reality it is easier and potentially more efficient to do both steps concurrently, thus you select two parents, breed them (Crossover) and repeat until a new pool is constructed.</p>
<p>Parents can be selected in many ways, however usually the fitness of the parents is used in some way to select them. For example, in the research algorithm a method called roulette wheel selection was used <span class="citation" data-cites="Slides"></span>, in this method all chromosomes in the pool take up an area on a wheel proportional to the fitness of the chromosome. This created some issues within the research algorithm as the fitness function returns the total distance of the chromosome. Thus, the smaller the distance, the better the chromosome. In order to get the correct probability of selection, the fitnesses needed to be ‘inverted’. This was done with two equations: <br /><span class="math display"><em>i</em><em>n</em><em>v</em> = <em>m</em><em>i</em><em>n</em><em>F</em><em>i</em><em>t</em> + <em>m</em><em>a</em><em>x</em><em>F</em><em>i</em><em>t</em></span><br /> <br /><span class="math display"><em>p</em> = (<em>i</em><em>n</em><em>v</em> − <em>f</em><em>i</em><em>t</em><em>n</em><em>e</em><em>s</em><em>s</em>)/<em>t</em><em>o</em><em>t</em><em>a</em><em>l</em><em>I</em><em>n</em><em>v</em><em>F</em><em>i</em><em>t</em><em>n</em><em>e</em><em>s</em><em>s</em>.</span><br /> Where <span class="math inline"><em>i</em><em>n</em><em>v</em></span> is the ’Inversion constant’, <span class="math inline"><em>m</em><em>i</em><em>n</em><em>F</em><em>i</em><em>t</em></span> is the smallest/best fitness in the pool, <span class="math inline"><em>m</em><em>a</em><em>x</em><em>F</em><em>i</em><em>t</em></span> is the largest/worst fitness in the pool, <span class="math inline"><em>p</em></span> is the probability of selection, <span class="math inline"><em>f</em><em>i</em><em>t</em><em>n</em><em>e</em><em>s</em><em>s</em></span> is the fitness of a chromosome, and <span class="math inline"><em>t</em><em>o</em><em>t</em><em>a</em><em>l</em><em>I</em><em>n</em><em>v</em><em>F</em><em>i</em><em>t</em><em>n</em><em>e</em><em>s</em><em>s</em></span> is the sum of all inverted fitnesses in the pool.</p>
<p>Using these equations, the probability of selection for each chromosome in the pool could be calculated, thus allowing for parents to be selected from the pool using these probabilities.</p>
<h3 id="crossover">Crossover</h3>
<p><em>Step 1: The children start as duplicates of the parents that have been selected. Also a range of genes is randomly selected, in this example genes 3 to 5 and they are shown in green.</em> <br /><span class="math display">$$Parent\, 1: [0,3,\colorbox{green}{2,5,1},4]$$</span><br /> <br /><span class="math display">$$Parent\, 2: [1,3,\colorbox{green}{5,0,4},2]$$</span><br /> <br /><span class="math display">$$Child\, 1: [0,3,\colorbox{green}{2,5,1},4]$$</span><br /> <br /><span class="math display">$$Child\, 2: [1,3,\colorbox{green}{5,0,4},2]$$</span><br /> <em>Step 2: From the second child, the genes contained in selected range of the first parent are removed. The same thing is done to the first child using the second parent.</em> <br /><span class="math display">$$Parent\, 1: [0,3,\colorbox{green}{2,5,1},4]$$</span><br /> <br /><span class="math display">$$Parent\, 2: [1,3,\colorbox{green}{5,0,4},2]$$</span><br /> <br /><span class="math display">$$Child\, 1: [-,3,\colorbox{green}{2,-,1},-]$$</span><br /> <br /><span class="math display">$$Child\, 2: [-,3,\colorbox{green}{-,0,4},-]$$</span><br /> <em>Step 3: The remaining genes in the children must be moved outside the range selected in step 1, without changing the order the are in.</em> <br /><span class="math display">$$Parent\, 1: [0,3,\colorbox{green}{2,5,1},4]$$</span><br /> <br /><span class="math display">$$Parent\, 2: [1,3,\colorbox{green}{5,0,4},2]$$</span><br /> <br /><span class="math display">$$Child\, 1: [3,2,\colorbox{green}{-,-,-},1]$$</span><br /> <br /><span class="math display">$$Child\, 2: [3,0,\colorbox{green}{-,-,-},4]$$</span><br /> <em>Step 4: Finally the genes selected in the first parent are moved into the now open space in the second child. The same goes for the second parent and first child.</em> <br /><span class="math display">$$Parent\, 1: [0,3,\colorbox{green}{2,5,1},4]$$</span><br /> <br /><span class="math display">$$Parent\, 2: [1,3,\colorbox{green}{5,0,4},2]$$</span><br /> <br /><span class="math display">$$Child\, 1: [3,2,\colorbox{green}{5,0,4},1]$$</span><br /> <br /><span class="math display">$$Child\, 2: [3,0,\colorbox{green}{2,5,1},4]$$</span><br /></p>
<p>Crossover (also known as breeding) is when two chromosomes, called parents, are ‘crossed’ together to produce one or more children. There are many ways of doing this, from slicing the parents in half and swapping the ends, to more complicated methods like the one used in the research algorithm shown in Figure <a href="#fig:cross" data-reference-type="ref" data-reference="fig:cross">[fig:cross]</a>. These children are then used to replace the current pool, thus forming the next generation.</p>
<p>A certain percentage of the population in the pool, called elites, is not replaced during crossover. This fraction of the pool consists of the fittest chromosomes, thus allowing these chromosomes to survive into future generations. The only way an chromosome can be removed from the elites, is if a fitter chromosome is found to replace it.</p>
<h3 id="mutation">Mutation</h3>
<p><br /><span class="math display">$$Before: [0,3,\colorbox{green}{2},5,1,\colorbox{red}{4}]$$</span><br /> <br /><span class="math display">$$After: [0,3,\colorbox{red}{4},5,1,\colorbox{green}{2}]$$</span><br /></p>
<p>Every child produced in Section <a href="#crossover" data-reference-type="ref" data-reference="crossover">3.2.2</a> has a chance of mutation, this is when the chromosome is subjected to a small but random change. In the case of the research algorithm, a specific form of mutation called swap mutation was used where two genes within the chromosome are randomly selected and then swapped, this is shown in Figure <a href="#fig:mut" data-reference-type="ref" data-reference="fig:mut">[fig:mut]</a>. This particular method of mutation does not invalidate the tour a chromosome describes, since it does not cause duplicate cities nor does it remove cities. Also, in the research algorithm, a chance of mutating multiple times was used, with each subsequent mutation being less and less probable.</p>
<h2 id="termination">Termination</h2>
<p>The final step in the Genetic Algorithm is termination. At the end of every generation, it is questioned whether the GA has met a specific criterion, if it has then the GA terminates and the best solution in the gene pool is the solution you finish with, otherwise it continues and begins a new generation. The criteria for termination can be nearly anything and are usually rather specific to the problem, however there are some generic ones, for example having found a solution that is fitter than a given solution or having completed a given number of generations.</p>
<h2 id="the-research-framework">The Research Framework</h2>
<p>The Genetic Algorithm that was constructed for this research is divided into two components, the first being the Genetic Algorithm Framework, and the second being a script which integrates with the framework <span class="citation" data-cites="Code"></span>. The GAFramework is actually quite a simple program, it was designed for the research, however even though the research was specifically on the Traveling Salesman Problem, the GAF is capable of being used for any problem. It simply passes data to the scripts and provides the scripts some generic functionality such as a chromosome object and a loop function. The script is the main bulk of the program as it is responsible for defining and solving a specific problem. The script constructed to solve the research problems was designed to be a generic script for Traveling Salesman Problems, when provided with a raw text file containing either a distance matrix or the coordinates for each city, it will proceed to solve the problem regardless of size. The script can also be given variables such as the size of chromosome pool, or the percentage of the pool to make elites.</p>
<h1 id="SimpleTSP">Simple TSP</h1>
<p>In this section, a small symmetric TSP consisting of only 6 cities will be solved using some of the simpler and more effective of the traditional methods: first by applying a modified Hungarian Algorithm, then via a Binary Integer Program (BIP) in Excel. After that, the problem will be solved via the GA constructed in section <a href="#WisGA" data-reference-type="ref" data-reference="WisGA">3</a>. In the last part of this section the performance of all 3 of the methods will be discussed.</p>
<h2 id="problem-definition">Problem Definition</h2>
<p>As mentioned before, the small problem consists of 6 cities, named A to F, with the following coordinates:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">A (3, 0.5)</td>
<td style="text-align: left;">C (6, 3.5)</td>
<td style="text-align: left;">E (8.5, 6)</td>
</tr>
<tr class="even">
<td style="text-align: left;">B (1, 3.5)</td>
<td style="text-align: left;">D (2.5, 7)</td>
<td style="text-align: left;">F (10, 1.5)</td>
</tr>
</tbody>
</table>
<figure>
<img src="6citymap" id="6citymap" style="height:7.5cm" alt="" /><figcaption><em>6 city map</em><span label="6citymap"></span></figcaption>
</figure>
<p>These can be represented on a 2-dimensional map as shown in figure <a href="#6citymap" data-reference-type="ref" data-reference="6citymap">2</a>. Knowing the coordinates of the points, the distance between every pair of points can be calculated, using the formula <span class="math inline">$XY=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}$</span> for points <span class="math inline"><em>X</em>(<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>)</span> and <span class="math inline"><em>Y</em>(<em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>)</span>. The results can be represented as a matrix, where element in column <span class="math inline"><em>X</em></span> and row <span class="math inline"><em>Y</em></span> (as well as element in row <span class="math inline"><em>X</em></span> and column <span class="math inline"><em>Y</em></span>) represents distance <span class="math inline"><em>X</em><em>Y</em></span>. For the given points A to F the matrix is shown in figure <a href="#distancematrix" data-reference-type="ref" data-reference="distancematrix">3</a>. In the future, it will be referred to as ‘the distance matrix’.</p>
<figure>
<img src="distancematrix" id="distancematrix" style="height:6cm" alt="" /><figcaption><em>The distance matrix</em><span label="distancematrix"></span></figcaption>
</figure>
<p>Note that the diagonal, which corresponds to the distance between the city and itself, is not defined, since such a tour is not allowed.</p>
<h2 id="HA">Hungarian Algorithm</h2>
<p>The Hungarian Algorithm is a method designed for the assignment problem, which is a relaxation of the TSP. A modified version of it, also known as the Matrix Reduction method, or Little’s Algorithm, was introduced by John D.C. Little in 1963, in his article titled <em>An Algorithm For The Traveling Salesman Problem</em>. We will now proceed to solving our 6-city problem, while simultaneously explaining the algorithm in use.</p>
<p><span class="underline">Step 1: Row and column reduction</span></p>
<p>Begin with the distance matrix (figure <a href="#distancematrix" data-reference-type="ref" data-reference="distancematrix">3</a>). Identify the smallest element in every row, and subtract it from every element in that row; then do the same for every column. The resulting matrix will have a zero in each row and each column. As such, the original distance matrix reduces as shown in figure <a href="#dmreduced" data-reference-type="ref" data-reference="dmreduced">4</a>.</p>
<figure>
<img src="dmreduced" id="dmreduced" style="height:6cm" alt="" /><figcaption><em>Reduced distance matrix</em><span label="dmreduced"></span></figcaption>
</figure>
<p>In Little’s article, he elaborates on why this works, explaining:</p>
<p>“If a constant is subtracted from each element of the first row (of the distance matrix), that constant is subtracted from the cost of every tour. This is because every tour must include one and only one element from the first row. The relative costs of all tours, however, are unchanged and so the tour which would be optimal is unchanged. The same argument can be applied to the columns.” <span class="citation" data-cites="little"></span></p>
<p><span class="underline">Step 2: Penalty calculation</span></p>
<p>For each zero in the new matrix note the sum between the minimum element in the row and the minimum element in the column of that zero (omitting the zero itself). That number is called the penalty associated with the zero. Therefore, the penalty associated with the zero in position AB is 0.63, since the smallest element in row A is 0.63, and smallest element in column B is 0. Similarly, the penalty of the zero in position BD is 1.21, and so on. The complete matrix displaying all the penalties is shown in figure <a href="#dmpenalties" data-reference-type="ref" data-reference="dmpenalties">5</a>. It is interesting to note, that although Little’s work describes the same process, it does not refer to those numbers as ‘the penalties’.</p>
<figure>
<img src="dmpenalties" id="dmpenalties" style="height:5.9cm" alt="" /><figcaption><em>Reduced distance matrix with penalties</em><span label="dmpenalties"></span></figcaption>
</figure>
<p><span class="underline">Step 3: Row and column elimination</span></p>
<p>Select the zero with the highest penalty. If there is more than one zero with the same penalty, select arbitrarily. The row and column of that zero can be eliminated from the matrix, and its position noted down as part of the optimum tour. In our case the zero in position BD has the highest penalty. Therefore, BD is the first definitive road in the final optimum tour that we are working towards. Hence it can be eliminated from the matrix, as shown in figure <a href="#dmelimination2" data-reference-type="ref" data-reference="dmelimination2">6</a>. Note that in the new matrix, element DB becomes undefined, since it is no longer possible for that road to be selected.</p>
<figure>
<img src="dmelimination2" id="dmelimination2" style="height:5.8cm" alt="" /><figcaption><em>Elimination of the selected road from the matrix</em><span label="dmelimination2"></span></figcaption>
</figure>
<p><span class="underline">Step 4: Repeat steps 1 to 3</span></p>
<p>For the new matrix, repeat all the steps from the beginning: first row and column reduction, then penalty calculation, and row and column elimination, until reaching a 2x2 matrix. If no mistakes have been made, 3 elements will be zeros with penalty of zero, and the remaining element undefined. In such a matrix, only two roads are possible, and they will be the last entries on the list of roads, forming a complete tour. Our 6-city problem eventually reduces to the following 2x2 matrix:</p>
<figure>
<img src="2x2matrix" id="2x2matrix" style="height:2.5cm" alt="" /><figcaption><em>Last matrix of the algorithm</em><span label="2x2matrix"></span></figcaption>
</figure>
<p>With the following assignments already made:</p>
<p>B <span class="math inline">→</span> D,</p>
<p>A <span class="math inline">→</span> B,</p>
<p>C <span class="math inline">→</span> A,</p>
<p>E <span class="math inline">→</span> F.</p>
<p>We complete this list by selecting assignments F <span class="math inline">→</span> C and D <span class="math inline">→</span> E from figure <a href="#2x2matrix" data-reference-type="ref" data-reference="2x2matrix">7</a>, which gives us the following tour:</p>
<p>A <span class="math inline">→</span> B <span class="math inline">→</span> D <span class="math inline">→</span> E <span class="math inline">→</span> F <span class="math inline">→</span> C <span class="math inline">→</span> A</p>
<figure>
<img src="6citytour" id="6citytour" style="height:7.5cm" alt="" /><figcaption><em>Final tour</em><span label="6citytour"></span></figcaption>
</figure>
<p>Looking back at the distance matrix (figure <a href="#distancematrix" data-reference-type="ref" data-reference="distancematrix">3</a>), the total distance of this tour is 26.95. The full step-by-step process can be seen in the appendix (appendix <a href="#FullHA" data-reference-type="ref" data-reference="FullHA">8.1</a>).</p>
<h2 id="BIP">Binary Integer Program</h2>
<p>The optimum TSP tour can also be determined using a Binary Integer Program (BIP) formulation of the problem <span class="citation" data-cites="ORlecture"></span>, as shown below.</p>
<p>Let <span class="math inline"><em>x</em><sub><em>i</em><em>j</em></sub></span> be the distance between cities <span class="math inline"><em>i</em></span> and <span class="math inline"><em>j</em></span>, given by the distance matrix in figure <a href="#distancematrix" data-reference-type="ref" data-reference="distancematrix">3</a> and let <span class="math inline"><em>y</em><sub><em>i</em><em>j</em></sub></span> be the binary decision variable such that:</p>
<p><br /><span class="math display">$$y_{ij}= 
\begin{cases}
1, &amp; \text{if road $ij$ is part of the tour}\\
0 &amp; \text{otherwise}
\end{cases}$$</span><br /></p>
<p>Then, the BIP formulation of the TSP is:</p>
<p>Minimize:</p>
<p><span class="math inline"><em>z</em> = ∑<sub><em>i</em></sub>∑<sub><em>j</em></sub><em>x</em><sub><em>i</em><em>j</em></sub><em>y</em><sub><em>i</em><em>j</em></sub></span></p>
<p>such that:</p>
<p><span class="math inline">∑<sub><em>i</em></sub><em>y</em><sub><em>i</em><em>j</em></sub> = 1</span> for all <span class="math inline"><em>j</em></span>,</p>
<p><span class="math inline">∑<sub><em>j</em></sub><em>y</em><sub><em>i</em><em>j</em></sub> = 1</span> for all <span class="math inline"><em>i</em></span>,</p>
<p>And <span class="math inline"><em>y</em><sub><em>i</em><em>j</em></sub></span> binary for all <span class="math inline"><em>i</em></span>, <span class="math inline"><em>j</em></span>.</p>
<p>This can be implemented into Excel and solved using the Excel-solver function. Since nowhere in the current formulation of the problem there is a constraint that requires the solution to be one single connected tour, it is highly likely that the solution given by Excel will contain subtours. However, the TSP does not allow for subtours, so they need to be eliminated with additional constraints.</p>
<p>Using the distance matrix from figure <a href="#distancematrix" data-reference-type="ref" data-reference="distancematrix">3</a> for the <span class="math inline"><em>x</em><sub><em>i</em><em>j</em></sub></span> values, and after manually eliminating all subtours, the BIP gives the solution <span class="math inline"><em>z</em> = 26.95</span>, with tour A <span class="math inline">→</span> B <span class="math inline">→</span> D <span class="math inline">→</span> E <span class="math inline">→</span> F <span class="math inline">→</span> C <span class="math inline">→</span> A, which is the same result as the one obtained via the Hungarian Algorithm in section <a href="#HA" data-reference-type="ref" data-reference="HA">4.2</a>.</p>
<h2 id="genetic-algorithm">Genetic Algorithm</h2>
<p>Given the distance matrix in figure <a href="#distancematrix" data-reference-type="ref" data-reference="distancematrix">3</a>, a reasonable poolsize and generation number, for example 200 and 1000 respectively, the GA is able to find the same solution for the problem as the BIP and the Hungarian Algorithm every time.</p>
<p>The choice of poolsize is almost arbitrary, constrained only by a rather vague restriction of being ‘reasonable’. So, naturally, one might wonder what that means. For a small problem like the one in question this choice is fairly simple. For 6 cities, the GA can produce <span class="math inline">6! = 720</span> possible tours, which includes duplicates that start from different cities and ones that go in reverse directions. Removing those leaves <span class="math inline">$\frac{6!}{2\cdot{6}}=\frac{5!}{2}=60$</span> possible tours (recall the <span class="math inline">$\frac{(n-1)!}{2}$</span> formula). Hence, even with a poolsize as small as 60, an optimal solution is almost guaranteed in the initial pool already (almost, due to the randomness at the core of a GA). Increasing the poolsize will improve those chances, however if it is set too high there are some disadvantages. Section <a href="#Analysis" data-reference-type="ref" data-reference="Analysis">6</a> of this article will explain in more detail the benefits of increasing the poolsize, as well as the drawbacks.</p>
<h2 id="performance-evaluation">Performance Evaluation</h2>
<p>When looking at the efficiency of methods, the main factor to consider is the time taken to reach the optimum solution. In the case of the TSP, an optimum is not always possible, so it is sensible to consider just a reasonable solution. Luckily, with this problem, all 3 methods in question give the optimum solution.</p>
<p>Solving a TSP with the Hungarian algorithm takes a substantial amount of time, especially if it is done by hand. This is due to the fact that every newly reduced matrix has to be re-written every time to perform the next step (see appendix <a href="#FullHA" data-reference-type="ref" data-reference="FullHA">8.1</a>). Additionally, manual computations are prone to mistakes and miscalculations. As such, for the simple TSP it took a total of 2 hours to reach the optimum solution, excluding the 40 minutes it took to manually construct the distance matrix. This is a substantial amount of time, considering the problem consists of only 6 cities. Arguably, it could’ve taken less time to approach it with brute force: list all the tours and select the lowest one.</p>
<p>The Binary Integer Program, done in Excel, found that same solution in 2 seconds, but the preparations took approximately 30 minutes. These include formulating the problem with initial constraints and adding extra subtour elimination constraints where necessary.</p>
<p>The GA found the solution to this problem in under 2 seconds, which suggests that it is most efficient. However, the process of writing the program is by far the longest, spreading over several days, indicating that the GA is actually the most inefficient out of the 3 methods.</p>
<p>It must be noted that these values are not an objective measure of the efficiency of the methods. Surely, for each of the methods there are ways to decrease the time. For example, if the Hungarian Algorithm is not done manually, but instead programed on a computer, a significant amount of time can be saved, since the computer does calculations faster and does not make mistakes, or if the Genetic Algorithm is written by an expert, it may only require several hours of work, rather than several days. Therefore, the values give above are superficial and should not be taken as an accurate measure of efficiency, but rather a mere representation.</p>
<p>From this, the conclusion can be made, that in the case of a relatively small problem and easy access to a computer (with Excel-solver), the most efficient method is the BIP. However, as the problem gets larger, Excel-solver becomes insufficient, as it accepts only a limited number of variables. When that threshold is exceeded, the GA becomes most efficient. Additionally, if there is a large number of problems, the GA is more efficient than the BIP as well, because the same GA can work on any TSP, whereas a BIP needs a change of constraints for every individual one. The Hungarian Algorithm is never efficient, unless no computer is available for use.</p>
<h1 id="largeTSP">How does the GA perform on a TSP of a larger scale?</h1>
<p>Considering the characteristics of a Genetic Algorithm, one can assume that they are not the standard method to use on problems of such a small scale as the problem discussed in the previous section, since manual or traditional methods can give the solution as well. GAs hold their real value in problems of a larger scale. Here they are capable of giving a feasible solution, where most other methods fail to give one or are just highly inefficient. The constructed GA has proved itself capable of dealing with a simple TSP containing six cities, but how does it perform on a TSP of a larger scale? This section will discuss the answer to that question, explaining the obstacles encountered along the way.</p>
<p>The details of the TSP, such as the number of cities and their locations, will be addressed in section <a href="#tsp" data-reference-type="ref" data-reference="tsp">5.1</a>. Then in section <a href="#perf" data-reference-type="ref" data-reference="perf">5.2</a>, the performance of the GA on this TSP will be discussed. Since the total of possible tours was relatively low for the simple TSP, discussed in the previous section, the GA was capable of finding the optimal tour in every run. In this larger TSP however, the number of tours is significantly larger, which meant that the GA did not find the optimal tour in every run. This problem is known as premature convergence and is the topic of the section <a href="#premc" data-reference-type="ref" data-reference="premc">5.3</a>. A possible method to prevent premature convergence is the topic of section <a href="#incest" data-reference-type="ref" data-reference="incest">5.4</a> and in the last section the conclusions are discussed.</p>
<h2 id="tsp">A TSP containing 26 cities</h2>
<p>For this expansion it was decided to extend the problem to 26 cities. To make the problem more realistic, these 26 cities were selected to be located throughout the Netherlands.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">1 Amersfoort</td>
</tr>
<tr class="even">
<td style="text-align: left;">2 Amsterdam</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3 Apeldoorn</td>
</tr>
<tr class="even">
<td style="text-align: left;">4 Arnhem</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5 Assen</td>
</tr>
<tr class="even">
<td style="text-align: left;">6 Breda</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7 Den Haag</td>
</tr>
<tr class="even">
<td style="text-align: left;">8 Den Helder</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9 Eindhoven</td>
</tr>
<tr class="even">
<td style="text-align: left;">10 Emmen</td>
</tr>
<tr class="odd">
<td style="text-align: left;">11 Enschede</td>
</tr>
<tr class="even">
<td style="text-align: left;">12 Groningen</td>
</tr>
<tr class="odd">
<td style="text-align: left;">13 Haarlem</td>
</tr>
<tr class="even">
<td style="text-align: left;">14 Heerenveen</td>
</tr>
<tr class="odd">
<td style="text-align: left;">15 Heerlen</td>
</tr>
<tr class="even">
<td style="text-align: left;">16 ‘s-Hertogenbosch</td>
</tr>
<tr class="odd">
<td style="text-align: left;">17 Leeuwarden</td>
</tr>
<tr class="even">
<td style="text-align: left;">18 Lelystad</td>
</tr>
<tr class="odd">
<td style="text-align: left;">19 Maastricht</td>
</tr>
<tr class="even">
<td style="text-align: left;">20 Middelburg</td>
</tr>
<tr class="odd">
<td style="text-align: left;">21 Nijmegen</td>
</tr>
<tr class="even">
<td style="text-align: left;">22 Rotterdam</td>
</tr>
<tr class="odd">
<td style="text-align: left;">23 Tilburg</td>
</tr>
<tr class="even">
<td style="text-align: left;">24 Utrecht</td>
</tr>
<tr class="odd">
<td style="text-align: left;">25 Venlo</td>
</tr>
<tr class="even">
<td style="text-align: left;">26 Zwolle</td>
</tr>
</tbody>
</table>
<p><span id="26cities" label="26cities">[26cities]</span></p>
<p><img src="26cities" alt="image" /> <span id="map1" label="map1">[map1]</span></p>
<p>The 26 cities are listed in alphabetical order together with a map of the Netherlands (figure <a href="#map1" data-reference-type="ref" data-reference="map1">[map1]</a>), that marks all of their locations. The objective is thus to find the shortest route that visits all of these cities and returns to the starting point afterwards. The total number of possible tours here is calculated by the equation: <br /><span class="math display">$$n = \frac{(26-1)!}{2} =  7.755605e+24.$$</span><br /> This number is significantly larger than the 60 possible tours for the simple TSP, discussed in section 2. This is then also the reason why most other methods fail to give a solution or are just inefficient. The manual methods and traditional methods, discussed in the previous section, are excellent examples. The Hungarian Algorithm already took 2 hours to perform on a TSP, containing only six cities and even though it did give the optimal solution in the end, it is highly inefficient to apply to this TSP because of the time it would take. In addition, this algorithm is a manual method, which makes it susceptible for human errors. The BIP also fails to give a solution, because the number of integer variables exceeds the limit of the Microsoft Excel linear solver. Even without this limit of variables, a BIP would take a long time to construct, considering all the possible subtours that would have to be added to the program as constraints in order to make sure that the resulting tour meets the criteria, set by the TSP. All of these subtours have to be excluded by manually adding these constraints, which makes the BIP timewise an inefficient method. Therefore it is necessary to turn to other methods, such as Genetic Algorithms. Even though they are not bound to give the optimal solution, they are at least capable of giving a suitable tour that meets the criteria, set by the TSP.</p>
<h2 id="perf">The performance of the GA</h2>
<p>The first observation, when the GA was applied to the expanded TSP, was that the time for one run of the program had increased. Depending on the settings, such as the number of generations and the poolsize, the program now takes approximately a minute. Since one chromosome now consists of not 6, but 26 genes, it makes sense that the time for one run increased. One minute is still a relatively short amount of time to find a solution. Besides the short time, another benefit is that the GA did not need reconstructing in order to be applied to this expanded TSP. Because of the way the basic structure was programmed, this GA can be applied to any TSP, that sparks your interest given that you provide the necessary data, which consists of the number of cities and their distances to each other. For other methods, like the Hungarian Algorithm or the BIP, this does not hold.</p>
<p><span>r</span><span>0.5</span></p>
<p><img src="1406tour" style="width:50.0%" alt="image" /></p>
<p><span id="1406tour" label="1406tour">[1406tour]</span></p>
<p>The next observation was that, while the GA still converged to a solution in every run, these solutions differed from each other. They did not show the same tour nor did they share the same total distance. The solutions seemed to span a reach of approximately 100 kilometers, the lowest solution having a total distance of 1406 kilometer. The tour, belonging to this solution of 1406 kilometers, is shown in figure <a href="#1406tour" data-reference-type="ref" data-reference="1406tour">[1406tour]</a>. During the analysis of the constructed GA, the program never gave a tour with a lower distance than this 1406 kilometers. We therefore believe this solution could well be the optimal tour however, due to the large amount of possible tours, this cannot be said with full certainty.</p>
<p>In order to find out why the GA gave multiple solutions, a new variable was introduced to the program. This variable, named <em>leetChanges</em>, counts the number of times the best chromosome in the pool, meaning the chromosome with the lowest total distance, is changed. Additionally the program also outputs when the last elite change has occurred. The conclusion, drawn from analyzing this new variable, was that the program reached convergence too fast. The last change of the best solution in the pool nearly always occurred in the first quarter of the number of generations. For example, if the number of generations was set to a 1000 then in generation 200 the best solution was last changed. This means that in generation 201 up until 1000 the best solution always remained the same tour. However, this solution was not necessarily the tour with the lowest total distance, since for one run the solution came out with a total distance of 1547 kilometers and for another run the total distance was 1422 kilometers. Therefore the program does not converge to the optimal solution every time. The program suffered from premature convergence, which is the topic of the next section.</p>
<h2 id="premc">Premature Convergence</h2>
<p><span>r</span><span>0.5</span> <img src="PrematureConvergence" alt="image" /> <span id="PrematureConvergence" label="PrematureConvergence">[PrematureConvergence]</span></p>
<p>Premature convergence is when the GA converges too early, to a local optimum <span class="citation" data-cites="Slides"></span>. It can be visualized by figure <a href="#PrematureConvergence" data-reference-type="ref" data-reference="PrematureConvergence">[PrematureConvergence]</a>. This graph, representing a one-dimensional problem, shows multiple peaks, several being local optima and one being the global optimum. When the program converges to a local optimum, it is unlikely to get past that local optimum to a better solution. Due to the concept of “survival of the fittest”, the best solution in the pool has the highest chance of being selected as a parent. If that best solution is in the neighborhood of a local optimum, then the majority of its children will also be in the neighborhood of that local optimum. In the following crossovers, a pool is generated with more and more chromosomes that are clustered around this local optimum. In other words, the selected parents cannot create children that are superior than they are themselves. Therefore the GA will not get past the local optimum during crossover. Moreover, the population loses its diversity as the program goes through the set number of generations, this is believed to be the main reason for the occurrence of premature convergence <span class="citation" data-cites="Premconvergence"></span><span class="citation" data-cites="Popdiv"></span><span class="citation" data-cites="Congress"></span>.</p>
<p>To obtain a chromosome, which is better than the current best solution in the pool, mutation is the only hope. As already mentioned by equation, there are 7.755605e+24 possible tours if duplicates and mirrored solutions are excluded. The GA however, does not necessarily exclude duplicated and mirrored tours, therefore the number of tours that the GA accounts for is: 26! = 4.0329146e+26. The size of this number makes the chance of randomly mutating a tour to a better solution than a local optimum very small. Even changing the rate of mutation, thus making the mutation more frequent and aggressive, will not prevent premature convergence. It is therefore also a frequent problem, encountered when applying GAs to optimization problems.</p>
<h2 id="incest">Incest Prevention</h2>
<p>There are different methods of dealing with premature convergence. H. Pandey, A. Chaudhary and D. Mehrotra discuss 24 methods in their article <em>A comparative review of approaches to prevent premature convergence in GA</em><span class="citation" data-cites="Premconvergence"></span>. In this section one of those methods will be discussed, namely incest prevention. Incest prevention is preventing two identical parents from breeding. During a crossover where two identical solutions are selected as the parents, two children will be created that are both identical to their parents and to each other. By constantly breeding with two identical parents, the generated pool quickly loses its diversity, which is the main cause of premature convergence. Which part of the parents is selected does not influence the outcome of such a crossover. Take for example a crossover between two identical parents, both containig six indices:</p>
<p><br /><span class="math display"><em>Parent 1</em> = [0, 1, 2, 3, 4, 5]</span><br /> <br /><span class="math display"><em>Parent 2</em> = [0, 1, 2, 3, 4, 5]</span><br /></p>
<p>In the first crossover a part of the first parent is selected and the remaining indices are provided in the order they appear in the second parent. This could happen in the following way:</p>
<p><br /><span class="math display"><em>Parent 1</em> : [−,1, 2, 3, −, − ]</span><br /> <br /><span class="math display"><em>Parent 2</em> : [0, −,−,−,4, 5]</span><br /></p>
<p>This leads to: <br /><span class="math display"><em>Child 1</em> : [0, 1, 2, 3, 4, 5]</span><br /></p>
<p>From this first child, it can be easily seen that the second child will also be identical to the parents and its sibling. However, this only happens, when both of the parents are completely identical, meaning that both their tour and starting location have to be the same. For example a crossover between the parents, depicted below, does not necessarily lead to a child that is identical to the parents, even though they share the same tour:</p>
<p><br /><span class="math display"><em>Parent 1</em> = [0, 1, 2, 3, 4, 5]</span><br /> <br /><span class="math display"><em>Parent 2</em> = [2, 3, 4, 5, 0, 1]</span><br /> In the first crossover, where a subset from the first parent is selected and the remaining parts of the chromosome are given by the second parent, this could happen:</p>
<p><br /><span class="math display"><em>Parent 1</em> : [−,1, 2, 3, −, − ]</span><br /> <br /><span class="math display"><em>Parent 2</em> : [−,−,4, 5, 0,  − ]</span><br /> This leads to: <br /><span class="math display"><em>Child 1</em> : [4, 1, 2, 3, 5, 0]</span><br /></p>
<p>Even though both parents contained the same tour, their child does not share it. Incest prevention therefore focuses on only eliminating crossovers between two identical parents. Incest prevention therefore focuses on only eliminating crossovers between two identical parents.</p>
<p>In order to implement incest prevention in the GA, an adjusted form of tournament selection was used. The first parent is still selected by means of probability based on its fitness. However, the second parent is now selected by a tournament of a set number of chromosomes. The winner of the tournament is the chromosome that is most different to the already selected first parent. If all candidates in the tournament are identical to the first parent, the program will dismiss the tournament and start a new one. This process goes on until a different chromosome is found.</p>
<p>The result of implementing this into the GA was that it increased the time for one run of the program. With the same settings, the time about doubled. This large increase can only be explained by the tournaments, since they were the only addition to the GA. This gives a helpful insight in the GA, since it apparently has to run a high amount of tournaments. This means that in most of the tournaments candidates are selected that are identical to the already determined first parent. Although the incest prevention itself works, the GA still converges to local optima. The incest prevention therefore did not prevent premature convergence and since it causes a large increase in time, it is not recommended to use within this GA and has not been used in the next section.</p>
<h2 id="further-expanding-the-tsp">Further expanding the TSP</h2>
<p>The GA is more than capable of dealing with a further expansion of the TSP, since when it contained 26 cities it gave solutions in approximately a minute. Therefore in this section, the GA will be applied to a TSP containing 50 cities, still all located throughout the Netherlands. Here the number of possible tours is the extremely high value of: <br /><span class="math display">$$n = \frac{(50-1)!}{2} = 3.0414093e+62.$$</span><br /> To put this number in perspective, there are more possible tours for this problem than there are atoms in the earth. Moreover, the GA itself accounts for even more tours, namely <span class="math inline">50! = 3.0414093<em>e</em> + 64</span>. Considering that traditional methods, like the Hungarian Algorithm or the BIP, were concluded to be unsuitable for the TSP consisting of 26 cities, they can be concluded even more unsuitable for this TSP, containing 50 cities.</p>
<p>The first observation to note is again an increase in time. Where the GA took 1 minute to complete the set number of generations for a TSP of 26 cities, the GA now takes 6 minutes with the same settings. Yet 6 minutes is a very short amount of time if one considers the number of possibilities, given in the previous paragraph. The GA still suffers from premature convergence and in order to work around that issue, the GA was set to run 600 times, saving the final solutions to an external file. Out of all these runs, the best solution, given by the GA, was a tour of 1623 kilometers. This tour is shown in figure <a href="#1623tour" data-reference-type="ref" data-reference="1623tour">[1623tour]</a>. Because of the large number of possible tours, it cannot be said with certainty that this tour is in fact the global optimum.</p>
<p><img src="1623tour" alt="image" /> <span id="1623tour" label="1623tour">[1623tour]</span></p>
<h2 id="conclusions">Conclusions</h2>
<p>This section has dealt with the question: How does the GA perform on a problem of larger scale? This problem contained 26 cities located throughout the Netherlands. The GA was still capable of converging to a solution however, these solutions are not necessarily the optimal tour. In other words, the program suffered from premature convergence. One method was examined to prevent this from happening, but without success. It is also outside of the range of this research to prevent the premature convergence. While it is true that the GA will sometimes give a tour that is not the global optimum, the chance of selecting a better tour by random choice is very very low due to the sheer amount of possible tours.</p>
<h1 id="Analysis">Analysis</h1>
<p>The constructed Genetic Algorithm takes as input amongst other things a certain amount of parameters for a particular few functions inside the script. An example of such a parameter would be the number of generations the algorithm will run for. So far in other parts of this work, the value of these parameters were chosen arbitrarily, without any concern or second thoughts. In this section however, the effect of different values for these parameters will be observed and discussed. There are multiple parameters at play in the GA of which we will discuss the four main ones, namely: the poolsize, the amount of generations, the percentage of elites and finally the rate of mutation. Furthermore, the effects of the parameters will be judged on a few properties: The time taken to finish, the actual quality of the objective value and its consistency.</p>
<p>The means by which the effects of the parameters are observed is in essence very straight-forward. The GA has been run thousands of times of which every subsequent trial differs from the previous one only in a small change in one of the parameters. For example, the poolsize has been set to 10 and afterwards increases by 10 for every iteration until a certain criterion is met. The way this has been accomplished is by running a for-loop on a system that keeps changing a parameter and then running the GA while the results of the GA are forwarded to an external file. From the extracted data a multitude of statements can be made about the properties of the GA. A simple example of such a statement would be the correlation between poolsize and total time taken. From a different and more practical perspective, one could wonder if and how to change the parameters for the optial performance of the GA.</p>
<h2 id="the-poolsize">The Poolsize</h2>
<p>To analyse the effect of changes in the poolsize on the program, the GA was executed with a poolsize of 10 to 1000 in steps of 10. However, since the GA still relies on random events at its core, the GA was not simply run once for a specific poolsize but 15 times instead. This to was to significantly reduce the chance of getting irregular results. Of these 15 trials, the average is taken of their objective value and other interesting statistics such as the time it took, while also selecting the most-and least optimal one for later reference.</p>
<figure>
<img src="OVP" id="OVP" style="height:6cm" alt="" /><figcaption><em>The Objective Value vs. The Poolsize</em><span label="OVP"></span></figcaption>
</figure>
<p>The actual graphing of the data generated can be seen in figure <a href="#OVP" data-reference-type="ref" data-reference="OVP">9</a> and it’s immediately very clear that the ‘objective value’ converges towards 1406 which is the assumed optimal tour in this TSP. The noteworthy thing here is that an increase in poolsize has minimal effect on the expected objective value, but more on the spread of the points.</p>
<p>Now let’s take a look at the graphing of the poolsize against the time taken. Figure <a href="#CTP" data-reference-type="ref" data-reference="CTP">10</a> follows a surprisingly smooth curve which clearly is not linear, but it’s hard to tell what relation it follows. The current guess is that it is a quadratic relation, but this will be investigated in a program designed for curve-fitting.</p>
<figure>
<img src="CTP" id="CTP" style="height:6cm" alt="" /><figcaption><em>The Computation Time vs. The Poolsize</em><span label="CTP"></span></figcaption>
</figure>
<p>While the seemingly quadratic relation has not been proven via a logical statement using the properties of the code, it can be seen in figure <a href="#LPPC" data-reference-type="ref" data-reference="LPPC">11</a> that the data so far does fit a quadratic relation very nicely. Maybe even more convincing is what happens in the next figure <a href="#LPPP" data-reference-type="ref" data-reference="LPPP">12</a> where the curving-software is asked to predict the graph when only giving a very small part of it. The accuracy of this prediction is very convincing for the case of a quadratic relation and even though it could very well turn out to be a very weak 4th power relation, it is assumed to be quadratic and treated as such.</p>
<figure>
<img src="LPPC" id="LPPC" style="height:6cm" alt="" /><figcaption><em>The quadratic fit</em><span label="LPPC"></span></figcaption>
</figure>
<figure>
<img src="LPPP" id="LPPP" style="height:6cm" alt="" /><figcaption><em>The predicted fit</em><span label="LPPP"></span></figcaption>
</figure>
<p>A noteworthy property of these and the upcoming graphs is that they are very spiky, even after having taken an average. These spikes are in essence a reminder that the GA is a program that depends on randomness. Furthermore, the fact that the GA depends on randomness is exactly the reason why those spikes will never disappear. They might decline in amplitude and reduce their frequency, but since they are products of random events, their absence can never be guaranteed. Just like it will also be possible for any amount of coins to all toss heads, no matter how many there are.</p>
<p>One way to reduce the spikes would be to repeatedly run the GA and consider the whole data-set instead of just a singular value. Another, more efficient way, is to optimize the input parameters. In the case of poolsize it can already be seen that an increase reduces the spikes in the objective value.</p>
<h2 id="the-amount-of-generations">The amount of generations</h2>
<p>The way that the effect of the generations parameter has on the performances of the GA has been analysed much like that of the poolsize and the first part is the effects of changes in the amount of generations versus the the time spent computing of which the graph can be seen in figure <a href="#CTG" data-reference-type="ref" data-reference="CTG">13</a>.</p>
<figure>
<img src="CTG" id="CTG" style="height:6cm" alt="" /><figcaption><em>The Computation Time vs. The amount of Generations</em><span label="CTG"></span></figcaption>
</figure>
<p>The relation between the two can clearly be seen to be proportional. This makes sense intuitively since if the amount of generations would be doubled and the amount of calculations per generation would remain the same, then the total amount of calculations and therefore the time needed to do the calculations would double as well, hence the linear relation.</p>
<p>Figure <a href="#OVG" data-reference-type="ref" data-reference="OVG">14</a> yields something interesting, because in contrary to the same graph of the poolsize, it does not reduce its spikes when the amount of generations increase.</p>
<p>This can be explained by considering that after a certain point the GA will have converged to some optimum and further generations will only have a negligible effect on finding a better optimum. Instead the GA will stick with the optimum it has found for the rest of the extra generations.</p>
<figure>
<img src="OVG" id="OVG" style="height:6cm" alt="" /><figcaption><em>The Objective Value vs. The amount of Generations</em><span label="OVG"></span></figcaption>
</figure>
<h2 id="the-percentage-of-elites">The percentage of elites</h2>
<p>The effects on the program of different values of the percentage of elites has been analysed by considering how the computing time and the objective value behave and more specifically, the quality of the objective value and its standard deviation.</p>
<p>It can be seen in figure <a href="#OVEP" data-reference-type="ref" data-reference="OVEP">15</a> that the relation between the objective value and the elites percentage is quite stable. That is, if the outer edges are not considered because both extremes result in very poor convergence.</p>
<figure>
<img src="OVEP" id="OVEP" style="height:6cm" alt="" /><figcaption><em>The Objective Value vs. The Percentage of Elites</em><span label="OVEP"></span></figcaption>
</figure>
<p>The reason that the side with too small a percentage of elites converges significantly worse than that with other values for this parameter, is because the program is effectively completely missing out on elites which are a vital part of the GA. Then the question arises why it does not work with higher values for the percentage of elites, this is because the elites are not susceptible to change over the course of the generations. In other words, the GA barely gets to apply the very reason why it is even considered: a gradual increase of the quality of the solution over the course of many generations by combining and mutating the current generation.</p>
<p>Figure <a href="#CTEP" data-reference-type="ref" data-reference="CTEP">16</a> shows a linear but decreasing relation between the percentage of elites and the computing time. This happens since the elites are not susceptible to change and therefore the GA will skip more and more of the computations the larger the percentage of elites becomes. Thus one should be careful about the illusion that a higher percentage of elites leads to a faster program. Instead the program simply does less calculations.</p>
<figure>
<img src="CTEP" id="CTEP" style="height:6cm" alt="" /><figcaption><em>The Computation Time vs. The Percentage of Elites</em><span label="CTEP"></span></figcaption>
</figure>
<p>Finally, figure <a href="#SDEP" data-reference-type="ref" data-reference="SDEP">17</a> shows the standard deviation of the objective value for different values for the percentage of elites. It can be seen that the percentage of elites obtains optimal consistency around 30 percent of the poolsize.</p>
<figure>
<img src="SDEP" id="SDEP" style="height:6cm" alt="" /><figcaption><em>The Standard Deviation vs. The Percentage of Elites</em><span label="SDEP"></span></figcaption>
</figure>
<h2 id="the-rate-of-mutation">The Rate of Mutation</h2>
<p>When considering the rate of mutation in the program, it is intuitively clear that this will have a minimal effect on the time needed to get the solution. However, it might deliver more interesting effects on the objective value and its standard deviation. The statement about the time needed can quickly be verified with figure <a href="#CTRM" data-reference-type="ref" data-reference="CTRM">18</a>, and indeed there it can be seen that there is no notable effect on the computation time.</p>
<figure>
<img src="CTRM" id="CTRM" style="height:6cm" alt="" /><figcaption><em>The Computation Time vs. The Rate of Mutation</em><span label="CTRM"></span></figcaption>
</figure>
<p>Figure <a href="#OVRM" data-reference-type="ref" data-reference="OVRM">19</a> shows the plotting of the objective value versus the rate of mutation. It can be seen that there seems to be a very slight decreasing factor there. But more notably is the little dip it attains around a rate of mutation of 30 percent. It does not look like much however, it should be kept in mind that the minimum this graph could ever obtain is 1406 and since this little dip comes consistently close to that particular value it is a very significant drop.</p>
<figure>
<img src="OVRM" id="OVRM" style="height:6cm" alt="" /><figcaption><em>The Objective Value vs. The Rate of Mutation</em><span label="OVRM"></span></figcaption>
</figure>
<p>The drop around the 30 percent mark can perhaps better be considered in Figure <a href="#SDRM" data-reference-type="ref" data-reference="SDRM">20</a> concerning the standard deviation versus the rate of mutation, and much like the previous graph there is a very notable drop around this value for the rate of mutation. The existence of this dip also immediately explains the dip in the previous graph since the program tries to get to 1406 all the time, but at these values it can do so more consistently hence the lower average of the objective value.</p>
<figure>
<img src="SDRM" id="SDRM" style="height:6cm" alt="" /><figcaption><em>The Standard Deviation vs. The Rate of Mutation</em><span label="SDRM"></span></figcaption>
</figure>
<h2 id="conclusions-of-the-analysis">Conclusions of the analysis</h2>
<p>At the beginning of the this section, three main properties were mentioned to be judged: the time taken to finish, the actual quality of the objective value and its consistency.</p>
<p>After having seen all the graphs and relations so far, some conclusions can be made with respect to the preferable settings for the optimal experience while handling the GA. For starters, to gain access to the better solutions in the solution space it is recommended to invest in both the poolsize and the amount of generations to overcome the threshold both of those parameters have at the lower values. Furthermore, the percentage of elites should not be in either of its extreme ends for this goal.</p>
<p>If the goal is to increase the potency of the GA while limiting the extra added time needed to finish, it is recommended to invest in the poolsize up until the slope of the quadratic relation catches up to that of the amount of generations and from there invest in the generations. This will be especially effective in bigger problems since for smaller problems chances are that there is no need to be careful about the time needed since it is negligible anyway.</p>
<p>Finally, considering the consistency of the GA, it already has been mentioned that both the percentage of elites and the rate of mutation give optimal consistency around a value of 30. Additionally, considering the poolsize and the amount of generations, the standard deviation of those parameters are shown in the figures <a href="#SDG" data-reference-type="ref" data-reference="SDG">21</a> and <a href="#SDP" data-reference-type="ref" data-reference="SDP">22</a>. It should be clear through the spikiness of the graphs that the standard deviation related to the amount of generations is generally constant in contrary to that of the poolsize since that seems to generally be decreasing. This means that the recommended settings for the goal of increasing the consistency can be concluded to be a minimal investment in the generations, a value between 30 and 50 for the elites percentage and a poolsize as big as the available computational power allows.</p>
<figure>
<img src="SDG" id="SDG" style="height:6cm" alt="" /><figcaption><em>The Standard Deviation vs. The amount of Generations</em><span label="SDG"></span></figcaption>
</figure>
<figure>
<img src="SDP" id="SDP" style="height:6cm" alt="" /><figcaption><em>The Standard Deviation vs. The Poolsize</em><span label="SDP"></span></figcaption>
</figure>
<h1 id="conclusions-1">Conclusions</h1>
<p>In the Introduction of this article, the following question was asked: How does a Genetic Algorithm perform when applied to the Travelling Salesman Problem? This article has provided the general concept of a GA, together with a detailed explanation of the construction and characteristics of such an algorithm for the TSP. Furthermore, the performance of the constructed GA has been discussed on small and larger TSPs.</p>
<p>For small problems, the GA tends to converge to the global optimum in every run and therefore it can be said that it performs excellently. More traditional methods, like the Hungarian Algorithm and the BIP, are also capable of finding the optimal tour. However, when a problem of a larger scale is given, these traditional methods become highly inefficient. This is because of the time they need to find a solution and in some cases the construction of these methods is infeasible. Even though the GA also needs more time, when the TSP expands, it is still capable of finding a solution within minutes, which is a lot faster than the other mentioned methods. Another benefit of the GA is that it can be applied to any TSP without a reconstruction when given the neccesary data, consisting of the number of cities and their distances to each other.</p>
<p>The GA however, does also have some disadvantages. One example is premature convergence, which occurs when applying the GA to a very large TSP. Another disadvantage is that the exact settings for optimal performance are closely related to the GA itself and take a considerable amount of time to determine. However, this disadvantage does have a definite solution, whereas in the case of premature convergence such a solution is hard to find. It is debatable whether premature convergence is even solvable or not, some believe that solving premature convergence would also result in solving the P versus NP problem to which the TSP is famously related.</p>
<p><span>12</span></p>
<p>D.L. Applegate, R.E. Bixby, V. Chvatal, and W.J. Cook. (2006). <em>The Traveling Salesman Problem: A Computational Study</em>. Princeton: Princeton University Press. Retrieved: June 4, 2017. Available: http://press.princeton.edu/chapters/s8451.pdf</p>
<p>R.K.B. Bhattacharjya. (2013, November 7). Introduction to Genetic Algorithms [Lecture slides from the Indian institute of Technology Guwahati]. Guwahati. Retrieved: May 12 2017. Available: https://www.iitg.ernet.in/rkbc/CE602/CE602/Genetic%20Algorithms.pdf</p>
<p>Google. <em>Google Maps</em> [Google Maps distances]. Retrieved: May 19, 2017.</p>
<p>B. de Jonge. (2016). [Lecture slides from the University of Groningen]. Operations Research 1, Lecture 7: Network Theory 2.</p>
<p>L. Juan, C. Zixing, and L. Jianqin. (2010). Premature convergence in genetic algorithm: Analysis and prevention based on chaos operator. <em>Proceedings of the 3rd World Congress on Intelligent Control and Automation</em>. 495-499.</p>
<p>Y. Leung, Y. Gao, and Z. Xu. (1997). Degree of Population Diversity - a Perspective on Premature Convergence in Genetic Algorithms and Its Markov Chain Analysis. <em>IEEE Transactions on Neural Networks</em>, <em>8</em>(5), 1165-1176.</p>
<p>J.D.C. Little, K.G. Murty, D.W. Sweeney and C. Karel. (1963). An algorithm for the traveling salesman problem. <em>Operations Research</em>, <em>11</em>(6), 972–989.</p>
<p>M. Mitchell. (1998). <em>An introduction to genetic algorithms.</em> Cambridge MA: MIT Press.</p>
<p>H.M. Pandey, A. Chadhary and D. Mehrota. (2014). A Comparative Review of Approaches to Prevent Premature Convergence in GA. <em>Applied Soft Computing</em>, <em>24</em>, 1047-1077.</p>
<p>B.R. Rajakumar and Aloysius George.(2013). APOGA: An Adaptive Population Pool Size Based Genetic Algorithm. <em>AASRI Procedia</em>, <em>4</em>, 288-96.</p>
<p>J.P. Ryan. (1992). <em>An algorithm for the solution of a traveling salesman problem to minimize the average time to demand satisfaction</em> [Unpublished master’s thesis]. Texas AM University. Retrieved: May 31, 2017.</p>
<p>O.H.P. Strik. (2017) <em>GAFramework</em> [The publication of the code]. Groningen. Available: https://github.com/Kranex/GAFramework</p>
<h1 id="appendix">Appendix</h1>
<h2 id="FullHA">Full Hungarian Algorithm</h2>
<p>As already mentioned in section <a href="#SimpleTSP" data-reference-type="ref" data-reference="SimpleTSP">4</a> of this article, the full Hungarian Algorithm takes an immense amount of time for any TSP of a reasonable scale. However, with a small problem like the one described in that section, it is not too problematic. What follows in this section is a full solution of the 6-city problem via the modified Hungarian Algorithm.</p>
<p>Begin with the distance matrix:</p>
<p><img src="distancematrix" style="height:5cm" alt="image" /></p>
<p>Perform the first step: row and column reduction. For that, subtract the smallest element of each row from its respective row, then do the same for columns, like so:</p>
<p><img src="1red0" style="height:5.2cm" alt="image" /></p>
<p>This results in the following matrix, called the reduced distance matrix:</p>
<p><img src="1red" style="height:6cm" alt="image" /></p>
<p>The second step of the algorithm is penalty calculation. The penalty of a zero is the sum between the smallest element in the row and the smallest element in the column in which that zero stands. The figure below shows these penalties:</p>
<p><img src="1pen" style="height:6cm" alt="image" /></p>
<p>Third step is elimination. The row and the column of the zero with the highest penalty get eliminated from the matrix, leaving behind a smaller matrix and a fraction of the final tour. Hence, row B and column D get eliminated:</p>
<p><img src="1elim2" style="height:6cm" alt="image" /></p>
<p>From this step we got a fraction of the final tour, namely road B <span class="math inline">→</span> D, and a smaller matrix, for which we now repeat steps 1-3. Note that element DB is undefined, since road B <span class="math inline">→</span> D is already taken.</p>
<p><span class="underline">Step 1:</span></p>
<p><img src="2red0" style="height:5.6cm" alt="image" /></p>
<p><span class="underline">Step 2:</span></p>
<p><img src="2pen" style="height:5.2cm" alt="image" /></p>
<p><span class="underline">Step 3:</span></p>
<p><img src="2elim3" style="height:5.2cm" alt="image" /></p>
<p>Therefore, we add road A <span class="math inline">→</span> B to the list and remove the value of element BA. In this case, row B has already been eliminated, so element BA already does not exist in the new matrix. Now repeat again. Notice that the newest matrix already contains a zero in every row and every column, so step 1 could be emitted.</p>
<p><span class="underline">Step 2:</span></p>
<p><img src="3pen" style="height:4.8cm" alt="image" /></p>
<p><span class="underline">Step 3:</span></p>
<p><img src="3elim4" style="height:4.5cm" alt="image" /></p>
<p>Hence, we note down road C <span class="math inline">→</span> A, and proceed with the 3x3 matrix.</p>
<p><span class="underline">Step 1:</span></p>
<p><img src="4red0" style="height:4.2cm" alt="image" /></p>
<p><span class="underline">Step 2:</span></p>
<p><img src="4pen" style="height:3.7cm" alt="image" /></p>
<p><span class="underline">Step 3:</span></p>
<p><img src="4elim5" style="height:3.6cm" alt="image" /></p>
<p>Road E <span class="math inline">→</span> F is now part of the tour, and element FE becomes undefined in the new 2x2 matrix. Now, one could proceed with the steps of the algorithm, but at this stage it is fairly simple to select the final tours: two are remaining and only two are possible: F <span class="math inline">→</span> C and D <span class="math inline">→</span> E, which correspond to elements FC and DE respectively. DC cannot be selected because it would leave FE, which is not possible, so FC and DE is the correct choice. Looking back, the following roads have been selected:</p>
<p>B <span class="math inline">→</span> D,</p>
<p>A <span class="math inline">→</span> B,</p>
<p>C <span class="math inline">→</span> A,</p>
<p>E <span class="math inline">→</span> F,</p>
<p>F <span class="math inline">→</span> C,</p>
<p>D <span class="math inline">→</span> E.</p>
<p>These roads can be compiled into a tour as follows:</p>
<p>A <span class="math inline">→</span> B <span class="math inline">→</span> D <span class="math inline">→</span> E <span class="math inline">→</span> F <span class="math inline">→</span> C <span class="math inline">→</span> A,</p>
<p>with city A chosen arbitrarily as the starting point. This completes the algorithm.</p>
</body>
</html>
